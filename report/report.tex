\documentclass[a4paper,12pt]{article}
\usepackage{graphicx} % For including images
\usepackage{amsmath}  % For mathematical formulas
\usepackage{lipsum}   % For dummy text
\usepackage{fancyhdr} % For header and footer customization
\usepackage{polyglossia} % For multilingual support
\usepackage{geometry} % For page layout
\usepackage{placeins}
\usepackage[colorlinks=true, citecolor=blue, urlcolor=blue]{hyperref}
\usepackage[backend=biber]{biblatex}

% Set the languages
\setmainlanguage{english}
\setotherlanguage{greek}

% Define fonts
\setmainfont{Linux Libertine}
% \newfontfamily\greekfont{Linux Libertine}
\setmonofont{UbuntuMono Nerd Font Mono}

% Page settings
\geometry{margin=1in}

\begin{document}
\begin{otherlanguage}{greek}

% Cover Page
\begin{titlepage}
    	\centering
    	\vspace*{2cm}

    	\Huge
    	\textbf{Προχωρημένα Θέματα Βάσεων Δεδομένων}

    	\vspace{0.5cm}
    	\LARGE
    	Εξαμηνιαία Εργασία \\
	\Large
    	Σχολή Ηλεκτρολόγων Μηχανικών και Μηχανικών Υπολογιστών, ΕΜΠ

    	\vspace{1.5cm}
    	\includegraphics[width=0.5\textwidth]{ntua.png}

    	\vfill

   	\Large
	\textbf{Ομάδα 7} \\
	Οικονόμου Νικόλαος (03120014) \\
	Ραφτόπουλος Μιχαήλ (03120114) \\
	\vspace{.2cm}
	\large
	\href{https://github.com/ntua-el20114/Advanced-Databases}{Αποθετήριο GitHub}\\

	\vfill

	\normalsize
    	Ιανουάριος 2025

    	\vspace{0.8cm}
\end{titlepage}

\newpage

% Main Content

\section*{Query 1}
	\addcontentsline{toc}{section}{Query 1}
	\FloatBarrier
	Εκτελέστηκε το query 1, τόσο με το DataFrame API, όσο και
	με το RDD API του Spark.
	Συγκρίνοντας τον χρόνο των δύο υλοποιήσεων, η υλοποίηση με DataFrame API
	αποδείχθηκε ταχύτερη\footnote{Σε αυτό το σημείο να αναφερθεί
	ότι στις διάφορες δοκιμές του χρόνου
	εκτέλεσης των queries τα αποτελέσματα παρουσιάζαν πολύ μεγάλη διακύμανση, που
	πιθανώς οφείλεται στο cloud περιβάλλον εκτέλεσης. Οι σχετικοί χρόνοι όμως
	ανάμεσα στις υλοποιήσεις παρέμεναν σταθεροί. Για το λόγο αυτό, 
	σημαντικότεροι είναι οι σχετικοί χρόνοι και όχι τα απόλυτα νούμερα.}.
	Το αποτέλεσμα αυτό είναι αναμενόμενο, καθώς το DataFrame API αποτελεί μια
	υψηλωτερη αφαιρετικά διεπαφή, με πολλές βελτιστοποιήσεις να πραγματοποιούνται
	στο υπόβαθρο (από τον Catalyst Optimizer). Με το RDD API μπορούμε
	θεωρητικά να πετύχουμε την ίδια αποδοτικότητα 
	(αφού και το DataFrame API χρησιμοποιεί στο υπόβαθρο RDDs), 
	αλλά απαιτείται πολλή εμειρία και προσεκτικός χειρισμός.
	% Δημιουργείται νέο RDD για κάθε operation => περισσότερη μνήμη
	\begin{table}[h]
		\centering
		\begin{tabular}{cc}
			Age Group & Count \\
			\hline
			Adults & 121093 \\
			Young Adults & 33605 \\
			Children & 15928 \\
			Elderly & 5985
		\end{tabular}
		\caption{Αποτελέσματα query 1.}
	\end{table}
	\FloatBarrier

\section*{Query 2}
	\addcontentsline{toc}{section}{Query 2}
	\FloatBarrier
	\par{(α)} Υπολογίστηκαν για κάθε έτος τα 3 Αστυνομικά Τμήματα με το υψηλότερο
	ποσοστό κλεισμένων υποθέσεων και ταξινομήθηκαν ανά έτος και ανά ποσοστό.
	Χρησιμοποιήθηκαν δύο διαφορετικά APIs του Spark: το DataFrame API και το SQL
	API. Μετά από αρκετές επαναλήψεις, η υλοποίσηση με SQL API αποδείχθηκε 
	ταχύτερη από το αυτήν με DataFrame API. Θεωρητικά δε θα αναμέναμε ουσιαστική
	διαφορά μεταξύ των δύο, καθώς αποτελούν απλά διαφορετικές διεπαφές του ίδιου
	optimizer. Η απόκλιση λοιπόν των δύο υλοποιήσεων μάλλον οφείλεται στον τρόπο
	που αυτές είναι γραμμένες, με τον κώδικα σε DataFrames να οδηγεί σε περισσότερα
	operations.
	\par{(β)} Σε αυτό το σημείο, έγινε η μετατροπή των δεδομένων εισόδου από 
	\texttt{.csv} σε \texttt{.parquet}. Εκτελέστηκε η ίδια υλοποίηση SQL,
	χρησιμοπιώντας το δεύτερο format. Η υλοποίηση με τα δεδομένα σε
	\texttt{.parquet} ήταν ταχύτερη. Αυτό είναι αναμενόμενο, καθώς το 
	\texttt{.parquet} αποτελεί έναν τύπο αρχείου σχεδιασμένο για κατανεμημένα
	filesystems.
	\begin{table}[h]
		\centering
		\begin{tabular}{cccc}
			year & AREA NAME & closed\_rate & \# \\
			\hline
			2010 & Rampart & 32.84713448949121 & 1 \\
			2010 & Olympic & 31.515289821999087 & 2 \\
			2010 & Harbor & 29.36028339237341 & 3 \\
			2011 & Olympic & 35.0400600901352 & 1 \\
			2011 & Rampart & 32.496447181430604 & 2 \\
			...
		\end{tabular}
		\caption{Aποτελέσματα query 2 (φαίνονται μόνο οι 
		πρώτες γραμμές).}
	\end{table}
	\FloatBarrier

\section*{Query 3}
	\addcontentsline{toc}{section}{Query 3}
	\FloatBarrier
	Ύστερα από χρήση της μεθόδου \texttt{.explain()} στα διαφορετικά joins που πραγματοποιούνται σε αυτό το query, πήραμε τα παρακάτω αποτελέσματα για τις επιλογές που κάνει ο Catalyst Optimizer του Spark:
\begin{itemize}
    \item Για Join μεταξύ Census και Income Dataset (μικρός πίνακας) χρησιμοποιεί \textbf{BroadcastHash Join}. Η επιλογή βγάζει νόημα, αφού το broadcast join αξιοποείται σε περιπτώσεις όπως αυτήν, δηλαδή για συνένωση μεγάλου με μικρό πίνακα.
    \item Για Join μεταξύ Crimes και Census Dataset χρησιμοποιεί \textbf{Range Join}. Η επιλογή είναι λογική αφού αξιοποείται σε περιπτώσεις με αριθμητικές τιμής όπως στην συγκεκριμένη που προσπαθεί να ταιριάξει τις συντεταγμένες των εγκλημάτων με την γεωμετρία του κάθε block. Είναι, λοιπόν, η πλέον κατάλληλη μέθοδος συνένωσης μεταξύ δύο dataset που συνδέονται με σχέσεις του τύπου:\newline
	    $$\leq, \geq, <, > \text{ή BETWEEN}$$
    \item Για Join μεταξύ των αποτελεσμάτων από τα δύο παραπάνω datasets χρησιμοποιεί \textbf{SortMerge Join}. Η επιλογή είναι αποδεδειγμένα καλή για συνθήκες ισότητας όπως στην συγκεκριμένη που γίνεται με βάση το κλειδί "COMM".
\end{itemize}
\vspace{0.3cm}
\subsubsection*{Χρόνοι εκτέλεσης}
Οι χρόνοι εκτέλεσης χωρίς την εφαρμογή κάποιου \textbf{.hint()} είναι:
\begin{itemize}
    \item Φόρτωση δεδομένων: \textbf{18.56} seconds
    \item Μέσο εισόδημα ανά άτομο σε κάθε περιοχή: \textbf{16.77} seconds
    \item Εγκλήματα ανά άτομο σε κάθε περιοχή: \textbf{45.58} seconds
    \item Συνένωση τελικών αποτελεσμάτων: \textbf{22.53} seconds
\end{itemize}
\vspace{0.3cm}
Παρακάτω βλέπουμε τον πίνακα με την εφαρμογή των διαφορετικών hints για τα επιλεγμένα Join operations (σημειώνεται πως ο χρόνος φόρτωσης των δεδομένων ήταν πάνω κάτω ο ίδιος σε όλες τις εκτελέσης ~18 sec).
\vspace{0.2cm}
\begin{table}[ht]
\centering
	\fontsize{8pt}{10pt}\selectfont
\begin{tabular}{ccccc}
CODE PART & BROADCAST & MERGE & SHUFFLE\_HASH & SHUFFLE\_REPLICATE\_NL \\ \hline
MEDIAN INCOME PER PERSON & \underline{15 (BroadcastHash)} & 17.4 (SortMerge) & 16.2 (ShuffledHash) & 16.3 (BroadcastHash) \\ 
CRIMES PER PERSON        & (Spark crushes)    & 40.5 (Range)      & \underline{37.6 (Range)}         & 38.5 (Range)         \\ 
FINAL MERGE              & 22.2 (BroadcastHash) & \underline{21.5 (SortMerge)} & 23.1 (ShuffledHash) & 26.2 (BroadcastHash) \\ 
\end{tabular}
\caption{Comparison of Join Strategies}
\label{tab:join_comparison}
\end{table}
\vspace{0.2cm}
Υπογραμμισμένα είναι τα καλύτερα αποτελέσματα. Οι διαφορές δεν είναι μεγάλες αλλά υπάρχουν και ταυτίζονται με τις προτάσεις του catalyst optimizer. Αυτό βασίζεται στην αιτιολόγηση που δίνουμε και παραπάνω για τις επιλογές που κάνει και επιβεβαιώνεται από τα αποτελέσματα μας. Οι χρόνοι προήλθαν ως μέσος όρος διαφορετικων εκτελέσεων.\newline
Σημειώνουμε, επίσης, τις παρακάτω παρατηρήσεις:
\begin{itemize}
    \item Το Broadcast Join αποτυγχάνει στην συνένωση δύο μεγάλων Dataset, δηλαδή του Crimes με το Census, μιας και δεν μπορεί να το υποστηρίξει η μνήμη.
    \item Το Spark επιλέγει αυτόματα το Range Join για την συνένωση των δύο παραπάνω, λόγω της χρήσης της μεθόδου \textbf{ST\_Within}.
    \item Στην προσπάθεια να μετρήσουμε τους χρόνους εκτέλεσης έγινε εμφανής η στρατηγική του lazy evaluation, μιας και τα timer ακριβώς πριν και μετά την εντολή του join ήταν πολύ μικρά, αφού δεν συνέβαινε τότε κατά την διάρκεια της εκτέλεσης. Γι' αυτόν τον λόγο όπως φαίνεται και στον κώδικα υπολογίσαμε τον συνολικό χρόνο που έκανε το πρόγραμμα για το πρώτο μισό (Median per person ανά περιοχή), το δεύτερο μισό (Crimes per person ανά περιοχή) και τέλος την συνένωση των δύο (Final combined result). Αυτοί οι τελικοί χρόνοι που φαίνονται και στον πίνακα επηρεάζονταν αναλόγως και την στρατηγική Join που χρησιμοποιούσαμε.
\end{itemize}
	\begin{table}[h]
		\centering
		\begin{tabular}{ccccc}
			COMM & ... & Median Income Per Person & ... & 
			Crimes Per Person Ration \\
			\hline
			Adams-Normandie & & 8791.4583 & & 0.73693 \\ 
			Alsace & & 11239.50119 & & 0.55133 \\
			Angeles National Forest & & 28117.65 & & 11.35 \\
			...
		\end{tabular}
		\caption{Aποτελέσματα query 3 (φαίνονται μόνο οι 
		πρώτες γραμμές και επιλεγμένες στήλες).}
	\end{table}
	\FloatBarrier

\section*{Query 4}
	\addcontentsline{toc}{section}{Query 4}
	\FloatBarrier
	Τα αποτελέσματα σχετικά με την επίδοση του query για τα διαφορετικά configurations αναλύονται παρακάτω. Πριν από αυτό, χωρίς το μάθημα να αποτελεί μάθημα στατιστικής ανάλυσης θέλαμε να παρατηρήσουμε τις αξιοσημείωτες διαφορές μεταξύ των φτωχότερων και των πλουσιότερων περιοχών του Los Angeles. Το ένα ενδιαφέρον είναι συνολικός αριθμός των εγκλημάτων (άρα και των θυμάτων) που παρατηρούμε τουλάχιστον τάξη μεγέθους παραπάνω στις φτωχότερες περιοχές. Επίσης, ενδιαφέρον αποτέλεσμα αποτελούν οι φυλετικές διαφορές στα θύματα, πράγμα που απεικονίζει και τις φυλετικές διαφορές στους ίδιους τους κατοίκους της κάθε περιοχής με τις πλουσιότερες περιοχές να έχουν κύρια θύματα Λευκούς ("White") και τις φτωχότερες Ισπανόφωνες φυλές ("Hispanic/Latin/Mexican") και Αφροαμερικάνους ("Black").

Τα αποτελέσματα για τα διαφορετικά configuration μετά από μέσο όρο 10 εκτελέσεων για το καθένα φαίνονται παρακάτω:
\begin{itemize}
	\item 1 core/2GB memory: \textbf{7.559s}
	\item 2 cores/4GB memory: \textbf{7.182s}
	\item 4 cores/8GB memory: \textbf{7.006s}
\end{itemize}
Με βάση τα αποτελέσματα που πήραμε δεν φαίνεται να κλιμακώνει ο κώδικας μας. Αυτό μπορεί να οφείλεται σε πολλούς παράγοντες και αναλύουμε κάποιους από αυτόυς. Το μέγεθος των dataset δεν είναι πάρα πολύ μεγάλο με αποτέλεσμα το overhead του spark (data shuffling, setting up tasks) να ξεπερνά τα οφέλη που μπορεί να έχουν κάποια παραπάνω cores και extra μνήμη. Επίσης, είναι πιθανό ένα bottleneck του χρόνου εκτέλεσης να είναι το φόρτωμα των δεδομένων από το S3 πράγμα που είναι κοινό σε όλα τα configurations. Συνοπτικά δηλαδή, υπάρχει περίπτωση και τα "λιγότερα" resources να επαρκούν για τον υπολογισμό του ζητούμενο και γι' αυτό να μην κάνει μεγάλη διαφορά η προσθήκη μνήμης και πυρήνων.
\vspace{0.2cm}
Να σημειωθεί ότι αξιοποιούμε προηγουμένως υπολογισμένα αποτελέσματα του Median Income per Person (Query 3) για να ξεχωρίσουμε τις τρεις πλουσιότερες και τις τρεις φτωχότερες περιοχές του LA.
	\begin{table}[h]
		\centering
		\begin{tabular}{ccc}
			vict\_descent & total\_victims & ... \\
			\hline
			White & 8429 & \\
			Other & 1125 & \\
			Hispanic/Latin/Mexican & 868 & \\
			Unknown & 651 & \\
			...
		\end{tabular}
		\caption{Aποτελέσματα query 4 για την περίπτωση των
		περιοχών με το υψηλότερο κατά κεφαλήν εισόδημα 
		(φαίνονται μόνο οι 
		πρώτες γραμμές και επιλεγμένες στήλες).}
	\end{table}
	\FloatBarrier

	\begin{table}[h]
		\centering
		\begin{tabular}{ccc}
			vict\_descent & total\_victims & ... \\
			\hline
			Hispanic/Latin/Mexican & 47026 & \\
			Black & 17151 & \\
			White & 7265 & \\
			Other & 3256 & \\
			...
		\end{tabular}
		\caption{Aποτελέσματα query 4 για την περίπτωση των
		περιοχών με το υψηλότερο κατά κεφαλήν εισόδημα 
		(φαίνονται μόνο οι 
		πρώτες γραμμές και επιλεγμένες στήλες).}
	\end{table}
	\FloatBarrier
\newpage
\section*{Query 5}
	\addcontentsline{toc}{section}{Query 5}
	\FloatBarrier
	\par Πραγματοποιήθηκε η υλοποίηση του Query 5 και εκτελέστηκε με τα 3
	ζητούμενα configuration. Για τον υπολογισμό του χρόνου εκτέλεσης, το πρόγραμμα
	επαναλήφθηκε 10 φορές για κάθε configuration και υπολογίστηκε ο μέσος χρόνος για
	κάθε περίπτωση. Παρακάτω φαίνονται τα αποτελέσματα:
	\begin{itemize}
		\item 2 executors $\times$ 4 cores/8GB memory: \textbf{9.82s}
		\item 4 executors $\times$ 2 cores/4GB memory: \textbf{7.60s}
		\item 8 executors $\times$ 1 core/2GB memory: \textbf{7.25s}
	\end{itemize}
	\par Βλέπουμε ότι πολλοί «αδύναμοι» executors αποδίδουν καλύτερα απ' ο, τι λίγοι
	«ισχυροί». Αυτή η παρατήρηση δεν αποτελεί έκπληξη. Από τη «φύση» της, η
	κατανεμημένη βάση δεδομένων χρησιμοποιεί κατά κόρον την παραλληλοποίηση. Οι
	υψηλά παραλληλοποιήσιμες αυτές ενέργειες εποφελούνται από περισσότερες, έστω
	και πιο «αδύναμες», διεργσίες.
	\begin{table}[h]
		\centering
		\begin{tabular}{ccc}
			DIVISION & crime\_count & mean\_distance \\
			\hline
			HOLLYWOOD & 213080 & 2.269 \\
			VAN NUYS & 211457 & 3.181 \\
			WILSHIRE & 198150 & 2.921 \\
			SOUTHWEST & 186742 & 2.395 \\
			...
		\end{tabular}
		\caption{Aποτελέσματα query 5 (φαίνονται μόνο οι 
		πρώτες γραμμές).}
	\end{table}
	\FloatBarrier

% References
\FloatBarrier
\printbibliography

\end{otherlanguage}
\end{document}
